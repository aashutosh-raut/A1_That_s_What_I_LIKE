{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe (Gensim)\n",
    "\n",
    "For looking at word vectors, we'll use **Gensim**. **Gensim** isn't really a deep learning package. It's a package for for word and text similarity modeling, which started with (LDA-style) topic models and grew into SVD and neural word representations. But its efficient and scalable, and quite widely used.   We gonna use **GloVe** embeddings, downloaded at [the Glove page](https://nlp.stanford.edu/projects/glove/). They're inside [this zip file](https://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained GloVe embeddings trained on a very large corpus.\n",
    "# These embeddings are expected to outperform\n",
    "# custom-trained models due to scale and data diversity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "model = api.load('glove-wiki-gigaword-100') \n",
    "glove = api.load(\"glove-wiki-gigaword-100\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_analogy(a, b, c, model): \n",
    "    # Use gensim's built-in analogy via most_similar\n",
    "    if any(w not in model.key_to_index for w in (a, b, c)):\n",
    "        return None\n",
    "\n",
    "    for word, _ in model.most_similar(positive=[b, c], negative=[a], topn=10):\n",
    "        if word not in {a, b, c}:\n",
    "            return word\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the pre-trained GloVe model on word analogy tasks.\n",
    "# The results serve as an upper-bound benchmark\n",
    "# for comparison with custom-trained embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_analogies(file_path, model): #evaluate_analogies\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().lower()\n",
    "            if not line or line.startswith(\":\"):\n",
    "                continue\n",
    "\n",
    "            words = line.split()\n",
    "            if len(words) != 4:\n",
    "                continue\n",
    "\n",
    "            a, b, c, d = words\n",
    "\n",
    "            # Skip if any word is OOV\n",
    "            if any(w not in model.key_to_index for w in (a, b, c, d)):\n",
    "                continue\n",
    "\n",
    "\n",
    "            prediction = predict_analogy(a, b, c, model)\n",
    "\n",
    "            total += 1\n",
    "            if prediction == d:\n",
    "                correct += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy, correct, total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Spearman correlation between pre-trained\n",
    "# GloVe similarities and human similarity judgments.\n",
    "# Higher correlation reflects better semantic alignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_acc, syn_correct, syn_total= evaluate_analogies(\"past-tense.txt\", model) #evaluate on syntactic analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_acc, syn_correct, syn_total = evaluate_analogies(\"country-capital.txt\", model) #evaluate on semantic analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Window Size</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Syntactic Accuracy</th>\n",
       "      <th>Semantic accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skipgram (NEG)</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.554487</td>\n",
       "      <td>0.894433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Window Size Training Loss Training time  Syntactic Accuracy  \\\n",
       "0  Skipgram (NEG)           5             -             -            0.554487   \n",
       "\n",
       "   Semantic accuracy  \n",
       "0           0.894433  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = { #results dictionary\n",
    "    \"Model\": [\"Skipgram (NEG)\"],\n",
    "    \"Window Size\": [\"5\"],\n",
    "    \"Training Loss\": [\"-\"],\n",
    "    \"Training time\": [\"-\"],\n",
    "    \"Syntactic Accuracy\": [syntactic_acc],\n",
    "    \"Semantic accuracy\": [semantic_acc]\n",
    "}\n",
    "\n",
    "df_skipgram_neg = pd.DataFrame(results)\n",
    "df_skipgram_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
